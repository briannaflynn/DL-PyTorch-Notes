{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "import time\n",
    "\n",
    "def timeit(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        now = time.time()\n",
    "        retval = func(*args, **kwargs)\n",
    "        print('{} took {:.5f}s'.format(func.__name__, time.time() - now))\n",
    "        return retval\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    path = \"/work2/05515/bflynn/frontera/data/mnist.pkl.gz\"\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "# NB: Use training, not validation mean for validation set\n",
    "# Why? If you normalize the two datasets with differently, they'll be on \n",
    "# totally different scales from one another - won't be able to tell \n",
    "# the differences between images in both sets \n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why the hell do inits matter?\n",
    "\n",
    "And why you need a good one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(nan), tensor(nan))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the heck happened? Activation explosion!\n",
    "Let's ask the loop to break when our activations explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x = a @ x\n",
    "    if x.std() != x.std(): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only takes 28 iterations until our activations explode!\n",
    "\n",
    "What about if we initialize our activations with a scale that is really low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now every activation has vanished, to zero. **This is the reason why we couldn't train deep neural networks for so long - initializing them is challenging and you need to pick the right initialization or your activations get too big to handle (nan) or vanish entirely!**\n",
    "\n",
    "Some strategies to properly initialize - \n",
    "\n",
    "- use stdev that will make sure x and ax have the *same* scale\n",
    "- orthogonal matrix initializes weight, so x and ax would have same sum of squares by preserving the L2 norm\n",
    "- spectral normalization on matrix A (spectral norm is least possible number M such that ```torch.norm(A@x) <= M*torch.norm(x)``` so dividing A by this M insures you don't overflow. You can still vanish with this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier initialization\n",
    "\n",
    "TLDR: scale equal to ```1/math.sqrt(n_in)```, where ```n_in``` is the **number of inputs of our matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)/math.sqrt(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1108), tensor(4.8581))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaiming initialization\n",
    "\n",
    "PyTorch kaiming init for reference ( just an example )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 32 # number of hidden layers just an example\n",
    "l1 = nn.Conv2d(1, nh, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.kaiming_normal_(l1.weight, a=1.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All you need is a good init - paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layering matrix multiplication, relu, fully connect it forward and then backward to pass back the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Data (vars initialized above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a loss function, without it we can't train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss\n",
    "\n",
    "First, we will need to compute the softmax of our activations. This is defined by:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
    "\n",
    "or more concisely:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$ \n",
    "\n",
    "In practice, we will need the log of the softmax when we calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in code form: \n",
    "\n",
    "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you multiply by zero in a one hot encoded vector, doing nothing and also slow\n",
    "# faster way - what is the location of what you care about? which is one\n",
    "# Use the index of our actual! (the one in a one hot encoded matrix or vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred.shape # sm = softmax predictions\n",
    "# 50,000 for all images in training set, 10 for number of pred categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.6219, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6219, -2.1545, -2.2841], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], [5,0,4]] \n",
    "# works because pytorch does numpy advanced indexing!\n",
    "# integer array indexing\n",
    "\n",
    "# can pass a list for each dimension(2 dims, 2 lists)\n",
    "# first is the row indexes you want\n",
    "# second is the column indexes you want\n",
    "\n",
    "# returns 0,5 - 1,0 - 2,4\n",
    "# check that above and below 0,5 are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log likelihood function\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "# all row indexes, and targets is columns we want\n",
    "# include \"-\" before input - because negative log likelihood\n",
    "# then, take the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss is the negative log likelihood of softmax predictions, compared \n",
    "# to actual training (y_training)\n",
    "\n",
    "loss = nll(sm_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3255, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the formula \n",
    "\n",
    "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
    "\n",
    "gives a simplification when we compute the log softmax, which was previously defined as `(x.exp()/(x.exp().sum(-1,keepdim=True))).log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
    "\n",
    "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
    "\n",
    "where a is the maximum of the $x_{j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you go x.exp() - can get very big numbers\n",
    "# huge numbers in floating numbers on a computer, wildly inprecise\n",
    "# computer could thing two huge numbers 1000 apart are exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Training\n",
    "\n",
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb): return (torch.argmax(out, dim=1) == yb).float().mean()\n",
    "# grab argmax, which number in softmax is highest, index of that is our prediction\n",
    "# (index would be what category was predicted in the one hot encoded matrix)\n",
    "# check whether that's equal to the actual\n",
    "# take the mean, convert it to a float first (can't take mean of int in pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0150,  0.1370, -0.2861,  0.0937,  0.1024, -0.2856,  0.2808,  0.2718,\n",
       "         -0.3597,  0.1550], grad_fn=<SelectBackward>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3057, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1719)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb) \n",
    "# haven't trained our model yet, so the accuracy based on the \n",
    "# randomly initialized parameters is 10 ish percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5 # learning rate\n",
    "epochs = 1 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "- calculate predictions\n",
    "- calculate your loss\n",
    "- do backward pass\n",
    "- **subtract learning rate times gradients**\n",
    "- and then **zero the gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs+1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i : end_i]\n",
    "        yb = y_train[start_i : end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad*lr\n",
    "                    l.bias -= l.bias.grad*lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4112, grad_fn=<NllLossBackward>), tensor(0.8125))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using parameters and optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i+bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            loss = loss_func(model(xb), yb)\n",
    "\n",
    "            loss.backward()\n",
    "            ## with torch.no_grad() refactoring, replace with\n",
    "            # model.parameters\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4112, grad_fn=<NllLossBackward>), tensor(0.8125))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModule():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        # every time set an attribute, update a list of _modules wiht list of all modules I have\n",
    "    def __setattr__(self,k,v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "        \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters(): yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = DummyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__() ## it has to set up dummy modules _modules dictionary\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1:Linear(in_features=784, out_features=50, bias=True)\n",
      "l2:Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children(): print(f\"{name}:{l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__() # needed to set up module dictionary\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequentialModel(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sequential??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optim\n",
    "\n",
    "**Further refactoring**\n",
    "\n",
    "Let's replace our previous manually coded optimization step:\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()\n",
    "```\n",
    "\n",
    "and instead use just:\n",
    "\n",
    "```python\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): \n",
    "        self.params,self.lr=list(params),lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "                \n",
    "    # select only parameters that you want to optimize, and zero \n",
    "    # their gradients\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6651, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2818, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7735, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're developing ...\n",
    "\n",
    "Don't set a random seed - if there's variation going on in the model at different times, we want to see it. \n",
    "\n",
    "#### Don't want it to be shielded by setting one random seed that works well\n",
    "\n",
    "Though reproducibility is key, great for doing science, not how you should develop your models at the beginning. Developing your models, you want intuitive sense of:\n",
    "- is it stable?\n",
    "- how much variation do you expect?\n",
    "\n",
    "If you have a test where it fails every 100 times, you want to know that! \n",
    "\n",
    "Can help with verifying stability and working to improve stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "```python\n",
    "    xb = x_train[start_i:end_i]\n",
    "    yb = y_train[start_i:end_i]\n",
    "```\n",
    "\n",
    "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
    "\n",
    "```python\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x) # len of something - length of dataset now stored\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i] # return tuple of x[i] and y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6875)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self,ds, bs): self.ds, self.bs = ds,bs\n",
    "    # class that takes dataset and batch size, stores them away\n",
    "    # loop through range from 0 to size of datase\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): # up to 500000\n",
    "            yield self.ds[i:i+self.bs] # end at 1 + self. batch size\n",
    "            \n",
    "    # yield - co-routine \n",
    "    # have a function that doesn't return one thing once, \n",
    "    # return lots of things lots of times - each time you call next, return the next thing that is yielded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "assert xb.shape == (bs, 28*28)\n",
    "assert yb.shape == (bs, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs): # go through each epoch\n",
    "        for xb, yb in train_dl: # go through each batch, grabbing independent and dependent variables\n",
    "            pred = model(xb) # calculate the predictions\n",
    "            loss = loss_func(pred, yb) # calculate the losses\n",
    "            loss.backward() # calculate the gradients\n",
    "            opt.step() # update with the learning rate\n",
    "            opt.zero_grad() # reset the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want code to be this good as a researcher, because it gives you the freedom to try new cool stuff without bugs that you didn't know about, without interpretability by your domain expert colleagues, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0763, grad_fn=<NllLossBackward>), tensor(0.8438))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc > 0.7\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is still problematic because it's going through the training set in the same order every time\n",
    "\n",
    "We want the randomness of order for better generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
    "        \n",
    "    def __iter__(self): # grab random permutation if not already shuffled\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(small_ds, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(small_ds, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([7, 9, 4]), tensor([6, 8, 3]), tensor([5, 0, 1]), tensor([2])]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)\n",
    "# could change this if you want to add padding, etc\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "    # pass dataloader sampler, looping through with yield avoids memory issues\n",
    "    # grab indexes and ds at index, gives list of tensors, collate them into a single pair of tensors\n",
    "    # collate grabs x and y and glues them together on a new axis\n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4069, grad_fn=<NllLossBackward>), tensor(0.9219))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch's dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5548, grad_fn=<NllLossBackward>), tensor(0.8594))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PyTorch's `DataLoader`, if you pass `num_workers`, will use multiple threads to call your `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid\n",
    "\n",
    "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                # no backwards - not calculating gradients for the \n",
    "                # validation set\n",
    "                tot_loss += loss_func(pred, yb) # keep track of loss\n",
    "                tot_acc  += accuracy (pred,yb) # keep track of acc\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: Are these validation results correct if batch size varies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You need to actually weight according to the size of the minibatch\n",
    "if you get the accuracy and loss for minibatch of 1 vs minibatch of 10001, can't really compare the two\n",
    "\n",
    "However, this is how almost every library does it\n",
    "\n",
    "Does NOT work correctly when you batch size varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question - why do you have to zero out your gradients in pytorch?\n",
    "\n",
    "If we didn't zero out, when we go loss.backwards will add the new gradients to the existing gradients\n",
    "\n",
    "We often have lots of sources of gradients, lots of modules all connected together\n",
    "\n",
    "When we call backward we wouldn't want backward to zero the gradients\n",
    "\n",
    "We need the grad.zero after calling backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6399) tensor(0.8342)\n",
      "1 tensor(0.7041) tensor(0.8508)\n",
      "2 tensor(0.1889) tensor(0.9481)\n",
      "3 tensor(0.1857) tensor(0.9498)\n",
      "4 tensor(0.1762) tensor(0.9508)\n"
     ]
    }
   ],
   "source": [
    "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks \n",
    "\n",
    "Callbacks let you fully customize every one of the steps\n",
    "- Model\n",
    "- Loss\n",
    "- Gradients\n",
    "- Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "nh,bs = 50,64\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor out the connected pieces of info out of the fit() argument list\n",
    "\n",
    "`fit(epochs, model, loss_func, opt, train_dl, valid_dl)`\n",
    "\n",
    "Let's replace it with something that looks like this:\n",
    "\n",
    "`fit(1, learn)`\n",
    "\n",
    "This will allow us to tweak what's happening inside the training loop in other places of the code because the `Learner` object will be mutable, so changing any of its attribute elsewhere will be seen in our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl, c=None):\n",
    "        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n",
    "        \n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "        \n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data, lr=0.5, nh=50):\n",
    "    m = data.train_ds.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,data.c))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner has no logic at all - just a storage device for model, optimizer, loss function and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact same thing, except now we access our tools we need from \n",
    "# learn where we stored all our stuff in previously\n",
    "\n",
    "def fit(epochs, learn):\n",
    "    for epoch in range(epochs):\n",
    "        learn.model.train()\n",
    "        for xb,yb in learn.data.train_dl:\n",
    "            loss = learn.loss_func(learn.model(xb), yb)\n",
    "            loss.backward()\n",
    "            learn.opt.step()\n",
    "            learn.opt.zero_grad()\n",
    "\n",
    "        learn.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in learn.data.valid_dl:\n",
    "                pred = learn.model(xb)\n",
    "                tot_loss += learn.loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(learn.data.valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.1767) tensor(0.9460)\n"
     ]
    }
   ],
   "source": [
    "loss,acc = fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_batch(xb, yb, cb):\n",
    "    if not cb.begin_batch(xb,yb): return\n",
    "    loss = cb.learn.loss_func(cb.learn.model(xb), yb)\n",
    "    if not cb.after_loss(loss): return\n",
    "    loss.backward()\n",
    "    if cb.after_backward(): cb.learn.opt.step()\n",
    "    if cb.after_step(): cb.learn.opt.zero_grad()\n",
    "\n",
    "def all_batches(dl, cb):\n",
    "    for xb,yb in dl:\n",
    "        one_batch(xb, yb, cb)\n",
    "        if cb.do_stop(): return\n",
    "\n",
    "def fit(epochs, learn, cb):\n",
    "    if not cb.begin_fit(learn): return\n",
    "    for epoch in range(epochs):\n",
    "        if not cb.begin_epoch(epoch): continue\n",
    "        all_batches(learn.data.train_dl, cb)\n",
    "        \n",
    "        if cb.begin_validate():\n",
    "            with torch.no_grad(): all_batches(learn.data.valid_dl, cb)\n",
    "        if cb.do_stop() or not cb.after_epoch(): break\n",
    "    cb.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self): return True\n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    def begin_validate(self): return True\n",
    "    def after_epoch(self): return True\n",
    "    def begin_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    def after_backward(self): return True\n",
    "    def after_step(self): return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackHandler():\n",
    "    def __init__(self,cbs=None):\n",
    "        self.cbs = cbs if cbs else []\n",
    "\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn,self.in_train = learn,True\n",
    "        learn.stop = False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
    "        return res\n",
    "\n",
    "    def after_fit(self):\n",
    "        res = not self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_fit()\n",
    "        return res\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.learn.model.train()\n",
    "        self.in_train=True\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
    "        return res\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.learn.model.eval()\n",
    "        self.in_train=False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_validate()\n",
    "        return res\n",
    "\n",
    "    def after_epoch(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_epoch()\n",
    "        return res\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
    "        return res\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        res = self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
    "        return res\n",
    "\n",
    "    def after_backward(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_backward()\n",
    "        return res\n",
    "\n",
    "    def after_step(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_step()\n",
    "        return res\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     return self.learn.stop\n",
    "        finally: self.learn.stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def begin_fit(self,learn):\n",
    "        super().begin_fit(learn)\n",
    "        self.n_iters = 0\n",
    "        return True\n",
    "        \n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters>=10: self.learn.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "fit(1, learn, cb = CallbackHandler([TestCallback()])) # batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        if self('begin_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): return\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: return\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        if self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        for xb,yb in dl:\n",
    "            if self.stop: break\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        self.stop=False\n",
    "\n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn = epochs,learn\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            if self('begin_fit'): return\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
    "                if self('after_epoch'): break\n",
    "            \n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            f = getattr(cb, cb_name, None)\n",
    "            if f and f(): return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing\n",
    "\n",
    "We define two new callbacks: the Recorder to save track of the loss and our scheduled learning rate, and a ParamScheduler that can schedule any hyperparameter as long as it's registered in the state_dict of the optimizer. \n",
    "\n",
    "Hyperparameter scheduling - learning rate\n",
    "\n",
    "You can and should schedule everything - dropout amount, weight decay, learning rate, momentum, everything\n",
    "\n",
    "Different phases in the loss landscapes of neural nets - look very different at the start, middle, and end \n",
    "\n",
    "Very unlikely that you want the same things for all parts of training so being able to schedule things is a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Recorder(Callback): # at the start of fitting, sets losses and lrs to empty\n",
    "    def begin_fit(self): self.lrs,self.losses = [],[]\n",
    "\n",
    "        # when training append the current lr and loss\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr']) # this is the final layer group learning rate\n",
    "        self.losses.append(self.loss.detach().cpu())        \n",
    "\n",
    "    def plot_lr  (self): plt.plot(self.lrs)\n",
    "    def plot_loss(self): plt.plot(self.losses)\n",
    "\n",
    "class ParamScheduler(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, pname, sched_func): self.pname,self.sched_func = pname,sched_func\n",
    "\n",
    "    def set_param(self):\n",
    "        for pg in self.opt.param_groups: # layer groups = param groups; pytorch optimizer contains param_groups, loop through\n",
    "            pg[self.pname] = self.sched_func(self.n_epochs/self.epochs)\n",
    "    \n",
    "    # this says everytime we start a batch, run our scheduler\n",
    "    def begin_batch(self): \n",
    "        if self.in_train: self.set_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sched_lin(start, end):\n",
    "    def _inner(start, end, pos): return start + pos * (end-start)\n",
    "    return partial(_inner, start, end)\n",
    "# the function takes a start end and position of learning rate, returns a learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor this with a decorator\n",
    "\n",
    "def annealer(f):\n",
    "    def _inner(start, end): return partial(f, start, end)\n",
    "    return _inner\n",
    "\n",
    "@annealer\n",
    "def sched_lin(start, end, pos): return start + pos * (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decorator is a function that returns a function\n",
    "Takes the written function, passes it into the function called with the '@' sign, and replaces the definition of the function with whatever is returned"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sched_lin() # use shift - tab; see that it takes only start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = sched_lin(1,2)\n",
    "f(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other scheduler functions\n",
    "@annealer\n",
    "def sched_cos(start, end, pos): return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2\n",
    "@annealer\n",
    "def sched_no(start, end, pos):  return start\n",
    "@annealer\n",
    "def sched_exp(start, end, pos): return start * (end/start) ** pos\n",
    "\n",
    "def cos_1cycle_anneal(start, high, end):\n",
    "    return [sched_cos(start, high), sched_cos(high, end)]\n",
    "\n",
    "#This monkey-patch is there to be able to plot tensors\n",
    "torch.Tensor.ndim = property(lambda x: len(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annealings = \"NO LINEAR COS EXP\".split()\n",
    "\n",
    "a = torch.arange(0, 100)\n",
    "p = torch.linspace(0.01,1,100)\n",
    "\n",
    "fns = [sched_no, sched_lin, sched_cos, sched_exp]\n",
    "for fn, t in zip(fns, annealings):\n",
    "    f = fn(2, 1e-2)\n",
    "    plt.plot(a, [f(o) for o in p], label=t)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine different schedulers (might want a warm up and cool down type scheduler)\n",
    "def combine_scheds(pcts, scheds):\n",
    "    assert sum(pcts) == 1.\n",
    "    pcts = tensor([0] + listify(pcts))\n",
    "    assert torch.all(pcts >= 0)\n",
    "    pcts = torch.cumsum(pcts, 0)\n",
    "    def _inner(pos):\n",
    "        idx = (pos >= pcts).nonzero().max()\n",
    "        if idx == 2: idx = 1\n",
    "        actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])\n",
    "        return scheds[idx](actual_pos)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3,0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b0e3c10f890>]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, [sched(o) for o in p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to train at a high learning rate for a long time, but you also want to train at a very low learning rate for a long time, and you want a gentle learning rate at the beginning when things are fragile.\n",
    "\n",
    "Therefore, want cosine scheduler to warm up and cool down our learning rates as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train): self.metrics,self.in_train = listify(metrics),in_train\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tot_loss,self.count = 0.,0\n",
    "        self.tot_mets = [0.] * len(self.metrics)\n",
    "        \n",
    "    @property\n",
    "    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
    "    @property\n",
    "    def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb) * bn\n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [Recorder,\n",
    "        partial(AvgStatsCallback,accuracy),\n",
    "        partial(ParamScheduler, 'lr', sched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner(model_func, loss_func, data):\n",
    "    return Learner(*model_func(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_func(lr=0.5): return partial(get_model, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner(get_model, loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    _order=0\n",
    "    def set_runner(self, run): self.run=run\n",
    "    def __getattr__(self, k): return getattr(self.run, k)\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "    \n",
    "    def __call__(self, cb_name): # takes any callback that a user might make\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f(): return True # users can replace __call__ itself\n",
    "        return False # makes this more flexible\n",
    "\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False\n",
    "\n",
    "class CancelTrainException(Exception): pass # let peoples callbacks cancel at any of these levels \n",
    "class CancelEpochException(Exception): pass # example, can cancel one epoch but continue to the next one\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        self.in_train = False\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        try:\n",
    "            self.xb,self.yb = xb,yb\n",
    "            self('begin_batch')\n",
    "            self.pred = self.model(self.xb)\n",
    "            self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb)\n",
    "            self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.opt.step()\n",
    "            self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException: self('after_cancel_batch')\n",
    "        finally: self('after_batch')\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        try:\n",
    "            for xb,yb in dl: self.one_batch(xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn,self.loss = epochs,learn,tensor(0.)\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            self('begin_fit')\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
    "                self('after_epoch')\n",
    "            \n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit') \n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on use of Exceptions\n",
    "\n",
    "Exceptions in this usage allow the callback writer to stop any of the main parts from things happening.\n",
    "\n",
    "In this example, will use it to stop training in order to create a learning rate finder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    _order=1\n",
    "    def after_step(self):\n",
    "        print(self.n_iter)\n",
    "        if self.n_iter>=10: raise CancelTrainException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(cb_funcs=TestCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some other callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)\n",
    "        \n",
    "class Recorder(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.lrs = [[] for _ in self.opt.param_groups]\n",
    "        self.losses = []\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        for pg,lr in zip(self.opt.param_groups,self.lrs): lr.append(pg['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())        \n",
    "\n",
    "    def plot_lr  (self, pgid=-1): plt.plot(self.lrs[pgid])\n",
    "    def plot_loss(self, skip_last=0): plt.plot(self.losses[:len(self.losses)-skip_last])\n",
    "        \n",
    "    def plot(self, skip_last=0, pgid=-1):\n",
    "        losses = [o.item() for o in self.losses]\n",
    "        lrs    = self.lrs[pgid]\n",
    "        n = len(losses)-skip_last\n",
    "        plt.xscale('log')\n",
    "        plt.plot(lrs[:n], losses[:n])\n",
    "\n",
    "class ParamScheduler(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, pname, sched_funcs): self.pname,self.sched_funcs = pname,sched_funcs\n",
    "        \n",
    "    def begin_fit(self):\n",
    "        if not isinstance(self.sched_funcs, (list,tuple)):\n",
    "            self.sched_funcs = [self.sched_funcs] * len(self.opt.param_groups)\n",
    "\n",
    "    def set_param(self):\n",
    "        assert len(self.opt.param_groups)==len(self.sched_funcs)\n",
    "        for pg,f in zip(self.opt.param_groups,self.sched_funcs):\n",
    "            pg[self.pname] = f(self.n_epochs/self.epochs)\n",
    "            \n",
    "    def begin_batch(self): \n",
    "        if self.in_train: self.set_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Learning Rate Finder from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to also add something that saves the model before running this, and loads it back after running - **otherwise you'll lose your weights!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Find(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
    "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
    "        self.best_loss = 1e9\n",
    "    # in begin batch, uses exponential curve to set the learning rate    \n",
    "    def begin_batch(self): \n",
    "        if not self.in_train: return\n",
    "        pos = self.n_iter/self.max_iter\n",
    "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos # curve to set lr\n",
    "        for pg in self.opt.param_groups: pg['lr'] = lr\n",
    "    # after each step, checks to see if we've done more than the maximum number of iterations (default is 100)     \n",
    "    def after_step(self): # or, whether the loss is much worse than the best we've had \n",
    "        # if EITHER happens, we raise CancelTrainException, which cancels training\n",
    "        if self.n_iter>=self.max_iter or self.loss>self.best_loss*10:\n",
    "            raise CancelTrainException() # this cancels training once you've found your learning rate!\n",
    "        if self.loss < self.best_loss: self.best_loss = self.loss\n",
    "        # see if the loss is better than our best loss - if so, make this better loss our new loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fastai we also use exponential smoothing on the loss. For that reason we check for `best_loss*3` instead of `best_loss*10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner(get_model, loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(cb_funcs=[LR_Find, Recorder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.recorder.plot(skip_last=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only does less than 100 epochs, knnow around where we want to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make it Convolutional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to(train, valid):\n",
    "    m,s = train.mean(), train.std()\n",
    "    return normalize(train, m, s), normalize(valid, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = normalize_to(x_train, x_valid)\n",
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0001), tensor(1.))"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When refactoring, use ```Lambda``` layer that takes a basic function input and converts this to a layer that you can add to ```nn.Sequential```.\n",
    "\n",
    "Best to give a name to the function you're using inside of your Lambda (like flatten below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x): return self.func(x)\n",
    "    \n",
    "def flatten(x): return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes flat vector of size bs x 784, puts it back as batch of images in \n",
    "# 28 by 28 pixel resolution\n",
    "def mnist_resize(x): return x.view(-1,1,28,28) # .view resizes stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(data):\n",
    "    return nn.Sequential(\n",
    "        Lambda(mnist_resize),\n",
    "        nn.Conv2d(1, 8, 5, padding=2, stride=2), nn.ReLU(), #14\n",
    "        nn.Conv2d(8, 16, 3, padding=1, stride=2), nn.ReLU(), #7\n",
    "        nn.Conv2d(16, 32, 3, padding=1, stride =2), nn.ReLU(), #4\n",
    "        nn.Conv2d(32, 32, 3, padding=1, stride =2), nn.ReLU(), #2\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(flatten),\n",
    "        nn.Linear(32, data.c)\n",
    "    )\n",
    "\n",
    "# sequential model that contains a bunch of stride 2 convolutions\n",
    "# remember = input is 28 by 28\n",
    "# So after the first convolution, input is 14 (dividing 28 in half)\n",
    "# After the second convolution, input is 7 x 7\n",
    "# then 4 x 4, 2 x 2\n",
    "# Do average pooling of all the activations\n",
    "# flatten the results\n",
    "# pass it through a linear layer\n",
    "# Done!\n",
    "\n",
    "# Use Lambda here to resize our input and flatten our output, all within nn.Sequential itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [Recorder, partial(AvgStatsCallback, accuracy)]\n",
    "# partial means I'm treating the AvgStatsCallback class like a function\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr = 0.4) # specifying our optimizer, SGD \n",
    "learn = Learner(model, opt, loss_func, data) # Create our learner, ready for training \n",
    "run = Runner(cb_funcs = cbfs) # Run our model for training, pass in our callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.4463392578125, tensor(0.8516)]\n",
      "valid: [0.1054855224609375, tensor(0.9692)]\n",
      "train: [0.090247626953125, tensor(0.9725)]\n",
      "valid: [0.573334326171875, tensor(0.8687)]\n",
      "train: [0.0709869482421875, tensor(0.9785)]\n",
      "valid: [0.0633759765625, tensor(0.9822)]\n",
      "train: [0.0536051171875, tensor(0.9838)]\n",
      "valid: [0.06171480712890625, tensor(0.9827)]\n",
      "train: [0.047069716796875, tensor(0.9850)]\n",
      "valid: [0.18089202880859376, tensor(0.9560)]\n",
      "train: [0.0432188427734375, tensor(0.9860)]\n",
      "valid: [0.060241253662109376, tensor(0.9842)]\n",
      "train: [0.03713488525390625, tensor(0.9890)]\n",
      "valid: [0.05763778076171875, tensor(0.9833)]\n",
      "train: [0.03346739013671875, tensor(0.9891)]\n",
      "valid: [0.059824786376953126, tensor(0.9833)]\n",
      "5.42 s  85.1 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.03146709228515625, tensor(0.9899)]\n",
      "valid: [0.05890255737304687, tensor(0.9848)]\n"
     ]
    }
   ],
   "source": [
    "run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### that took a long time! Let's use our GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
