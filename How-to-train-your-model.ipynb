{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "import time\n",
    "\n",
    "def timeit(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        now = time.time()\n",
    "        retval = func(*args, **kwargs)\n",
    "        print('{} took {:.5f}s'.format(func.__name__, time.time() - now))\n",
    "        return retval\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    path = \"/work2/05515/bflynn/frontera/data/mnist.pkl.gz\"\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "# NB: Use training, not validation mean for validation set\n",
    "# Why? If you normalize the two datasets with differently, they'll be on \n",
    "# totally different scales from one another - won't be able to tell \n",
    "# the differences between images in both sets \n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why the hell do inits matter?\n",
    "\n",
    "And why you need a good one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(nan), tensor(nan))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the heck happened? Activation explosion!\n",
    "Let's ask the loop to break when our activations explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x = a @ x\n",
    "    if x.std() != x.std(): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only takes 28 iterations until our activations explode!\n",
    "\n",
    "What about if we initialize our activations with a scale that is really low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now every activation has vanished, to zero. **This is the reason why we couldn't train deep neural networks for so long - initializing them is challenging and you need to pick the right initialization or your activations get too big to handle (nan) or vanish entirely!**\n",
    "\n",
    "Some strategies to properly initialize - \n",
    "\n",
    "- use stdev that will make sure x and ax have the *same* scale\n",
    "- orthogonal matrix initializes weight, so x and ax would have same sum of squares by preserving the L2 norm\n",
    "- spectral normalization on matrix A (spectral norm is least possible number M such that ```torch.norm(A@x) <= M*torch.norm(x)``` so dividing A by this M insures you don't overflow. You can still vanish with this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier initialization\n",
    "\n",
    "TLDR: scale equal to ```1/math.sqrt(n_in)```, where ```n_in``` is the **number of inputs of our matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "x = torch.randn(512)\n",
    "a = torch.randn(512,512)/math.sqrt(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1363), tensor(7.0877))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaiming initialization\n",
    "\n",
    "PyTorch kaiming init for reference ( just an example )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 32 # number of hidden layers just an example\n",
    "l1 = nn.Conv2d(1, nh, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.kaiming_normal_(l1.weight, a=1.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All you need is a good init - paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layering matrix multiplication, relu, fully connect it forward and then backward to pass back the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Data (vars initialized above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a loss function, without it we can't train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss\n",
    "\n",
    "First, we will need to compute the softmax of our activations. This is defined by:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
    "\n",
    "or more concisely:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$ \n",
    "\n",
    "In practice, we will need the log of the softmax when we calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in code form: \n",
    "\n",
    "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you multiply by zero in a one hot encoded vector, doing nothing and also slow\n",
    "# faster way - what is the location of what you care about? which is one\n",
    "# Use the index of our actual! (the one in a one hot encoded matrix or vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred.shape # sm = softmax predictions\n",
    "# 50,000 for all images in training set, 10 for number of pred categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.9466, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9466, -2.2533, -2.4473], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], [5,0,4]] \n",
    "# works because pytorch does numpy advanced indexing!\n",
    "# integer array indexing\n",
    "\n",
    "# can pass a list for each dimension(2 dims, 2 lists)\n",
    "# first is the row indexes you want\n",
    "# second is the column indexes you want\n",
    "\n",
    "# returns 0,5 - 1,0 - 2,4\n",
    "# check that above and below 0,5 are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log likelihood function\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "# all row indexes, and targets is columns we want\n",
    "# include \"-\" before input - because negative log likelihood\n",
    "# then, take the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss is the negative log likelihood of softmax predictions, compared \n",
    "# to actual training (y_training)\n",
    "\n",
    "loss = nll(sm_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3448, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the formula \n",
    "\n",
    "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
    "\n",
    "gives a simplification when we compute the log softmax, which was previously defined as `(x.exp()/(x.exp().sum(-1,keepdim=True))).log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
    "\n",
    "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
    "\n",
    "where a is the maximum of the $x_{j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you go x.exp() - can get very big numbers\n",
    "# huge numbers in floating numbers on a computer, wildly inprecise\n",
    "# computer could thing two huge numbers 1000 apart are exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Training\n",
    "\n",
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb): return (torch.argmax(out, dim=1) == yb).float().mean()\n",
    "# grab argmax, which number in softmax is highest, index of that is our prediction\n",
    "# (index would be what category was predicted in the one hot encoded matrix)\n",
    "# check whether that's equal to the actual\n",
    "# take the mean, convert it to a float first (can't take mean of int in pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1760, -0.3334,  0.6334, -0.0093, -0.2983,  0.5190, -0.2911,  0.5797,\n",
       "         -0.0902,  0.1106], grad_fn=<SelectBackward>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3418, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0312)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb) \n",
    "# haven't trained our model yet, so the accuracy based on the \n",
    "# randomly initialized parameters is 10 ish percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5 # learning rate\n",
    "epochs = 1 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "- calculate predictions\n",
    "- calculate your loss\n",
    "- do backward pass\n",
    "- **subtract learning rate times gradients**\n",
    "- and then **zero the gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs+1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i : end_i]\n",
    "        yb = y_train[start_i : end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad*lr\n",
    "                    l.bias -= l.bias.grad*lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2007, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using parameters and optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i+bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            loss = loss_func(model(xb), yb)\n",
    "\n",
    "            loss.backward()\n",
    "            ## with torch.no_grad() refactoring, replace with\n",
    "            # model.parameters\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2007, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModule():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        # every time set an attribute, update a list of _modules wiht list of all modules I have\n",
    "    def __setattr__(self,k,v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "        \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters(): yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = DummyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__() ## it has to set up dummy modules _modules dictionary\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1:Linear(in_features=784, out_features=50, bias=True)\n",
      "l2:Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children(): print(f\"{name}:{l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__() # needed to set up module dictionary\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequentialModel(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sequential??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optim\n",
    "\n",
    "**Further refactoring**\n",
    "\n",
    "Let's replace our previous manually coded optimization step:\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()\n",
    "```\n",
    "\n",
    "and instead use just:\n",
    "\n",
    "```python\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): \n",
    "        self.params,self.lr=list(params),lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "                \n",
    "    # select only parameters that you want to optimize, and zero \n",
    "    # their gradients\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8076, grad_fn=<NllLossBackward>), tensor(0.8125))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3353, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9692, grad_fn=<NllLossBackward>), tensor(0.7500))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're developing ...\n",
    "\n",
    "Don't set a random seed - if there's variation going on in the model at different times, we want to see it. \n",
    "\n",
    "#### Don't want it to be shielded by setting one random seed that works well\n",
    "\n",
    "Though reproducibility is key, great for doing science, not how you should develop your models at the beginning. Developing your models, you want intuitive sense of:\n",
    "- is it stable?\n",
    "- how much variation do you expect?\n",
    "\n",
    "If you have a test where it fails every 100 times, you want to know that! \n",
    "\n",
    "Can help with verifying stability and working to improve stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "```python\n",
    "    xb = x_train[start_i:end_i]\n",
    "    yb = y_train[start_i:end_i]\n",
    "```\n",
    "\n",
    "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
    "\n",
    "```python\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x) # len of something - length of dataset now stored\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i] # return tuple of x[i] and y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244],\n",
       "         [-0.4244, -0.4244, -0.4244,  ..., -0.4244, -0.4244, -0.4244]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8750)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self,ds, bs): self.ds, self.bs = ds,bs\n",
    "    # class that takes dataset and batch size, stores them away\n",
    "    # loop through range from 0 to size of datase\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): # up to 500000\n",
    "            yield self.ds[i:i+self.bs] # end at 1 + self. batch size\n",
    "            \n",
    "    # yield - co-routine \n",
    "    # have a function that doesn't return one thing once, \n",
    "    # return lots of things lots of times - each time you call next, return the next thing that is yielded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "assert xb.shape == (bs, 28*28)\n",
    "assert yb.shape == (bs, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs): # go through each epoch\n",
    "        for xb, yb in train_dl: # go through each batch, grabbing independent and dependent variables\n",
    "            pred = model(xb) # calculate the predictions\n",
    "            loss = loss_func(pred, yb) # calculate the losses\n",
    "            loss.backward() # calculate the gradients\n",
    "            opt.step() # update with the learning rate\n",
    "            opt.zero_grad() # reset the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want code to be this good as a researcher, because it gives you the freedom to try new cool stuff without bugs that you didn't know about, without interpretability by your domain expert colleagues, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2686, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc > 0.7\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is still problematic because it's going through the training set in the same order every time\n",
    "\n",
    "We want the randomness of order for better generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
    "        \n",
    "    def __iter__(self): # grab random permutation if not already shuffled\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(small_ds, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(small_ds, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([4, 2, 7]), tensor([5, 6, 1]), tensor([0, 9, 3]), tensor([8])]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)\n",
    "# could change this if you want to add padding, etc\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "    # pass dataloader sampler, looping through with yield avoids memory issues\n",
    "    # grab indexes and ds at index, gives list of tensors, collate them into a single pair of tensors\n",
    "    # collate grabs x and y and glues them together on a new axis\n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANeElEQVR4nO3df6hc9ZnH8c/HH8XEiEaDmqTRtDf+sctizBpkRVmqJcUVIVZwacAlGwOpUKHVVVayQkUpyLKtgn8oKQaza9dSE7tKVYyEsP6CYvyxGhsbf5CNSW4SomASVLrRZ/+4J8s1uec7N3Nm5szmeb/gMjPnmXPOw5BPzpn5npmvI0IAjn8ntN0AgMEg7EAShB1IgrADSRB2IImTBrkz23z0D/RZRHii5Y2O7Lavsv1H2+/bvqPJtgD0l7sdZ7d9oqStkhZJ2iHpVUlLIuIPhXU4sgN91o8j+yWS3o+IDyPiT5J+LWlxg+0B6KMmYZ8t6aNxj3dUy77G9grbm2xvarAvAA01+YBuolOFo07TI2KVpFUSp/FAm5oc2XdImjPu8Tcl7WrWDoB+aRL2VyVdYPtbtr8h6QeSnupNWwB6revT+Ig4ZPtmSc9JOlHS6oh4p2edAeiprofeutoZ79mBvuvLRTUA/v8g7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJgU7ZjO7Mnz+/WL/llltqayMjI8V1p06dWqyvXLmyWD/99NOL9Weffba2duDAgeK66C2O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBLO4DoFp06YV69u3by/WzzjjjF6201M7d+6srZWuD5CktWvX9rqdFOpmcW10UY3tbZIOSPpS0qGIWNhkewD6pxdX0F0REft6sB0AfcR7diCJpmEPSettv2Z7xURPsL3C9ibbmxruC0ADTU/jL4uIXbbPlvS87Xcj4oXxT4iIVZJWSXxAB7Sp0ZE9InZVt3sl/VbSJb1oCkDvdR1226faPu3wfUnfk7S5V40B6K2ux9ltf1tjR3Np7O3Av0fEzzqsw2n8BE477bRi/ZlnninWP/7449raG2+8UVx3wYIFxfr5559frM+ZM6dYnzJlSm1tz549xXUvvfTSYr3T+ln1fJw9Ij6UVP5VBQBDg6E3IAnCDiRB2IEkCDuQBGEHkuArrmhkxowZxfrtt9/eVU2Sli1bVqyvWbOmWM+qbuiNIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMGUzWhk377yb42+/PLLtbVO4+ydvn7LOPux4cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo5Gpk+fXqyvXLmy623PmjWr63VxNI7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEvxuPovnzyxP1Pv7448X6vHnzamtbt24trrto0aJi/aOPPirWs+r6d+Ntr7a91/bmccvOtP287feq2/KVFQBaN5nT+EckXXXEsjskbYiICyRtqB4DGGIdwx4RL0j65IjFiyUd/k2gNZKu7XFfAHqs22vjz4mIUUmKiFHbZ9c90fYKSSu63A+AHun7F2EiYpWkVRIf0AFt6nbobY/tmZJU3e7tXUsA+qHbsD8laWl1f6mkJ3vTDoB+6TjObvsxSd+RNEPSHkk/lfQfkn4j6TxJ2yVdHxFHfog30bY4jR8yS5cuLdbvvvvuYn3OnDnF+ueff15bu+aaa4rrbty4sVjHxOrG2Tu+Z4+IJTWl7zbqCMBAcbkskARhB5Ig7EAShB1IgrADSfBT0seBadOm1dZuu+224rp33nlnsX7CCeXjwSeflEdcL7/88trau+++W1wXvcWRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9OPDII4/U1q677rpG2167dm2xfv/99xfrjKUPD47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zHgZGRkb5t+8EHHyzWX3nllb7tG73FkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCc/Tiwfv362tr8+fP7tm2p8zj8vffeW1vbtWtXVz2hOx2P7LZX295re/O4ZXfZ3mn7zerv6v62CaCpyZzGPyLpqgmW3xcRF1V/z/S2LQC91jHsEfGCpPIcPwCGXpMP6G62/VZ1mj+97km2V9jeZHtTg30BaKjbsD8oaUTSRZJGJf287okRsSoiFkbEwi73BaAHugp7ROyJiC8j4itJv5R0SW/bAtBrXYXd9sxxD78vaXPdcwEMB0dE+Qn2Y5K+I2mGpD2Sflo9vkhSSNom6YcRMdpxZ3Z5Z+jKlClTamuPPvpocd2LL764WD/vvPO66umw3bt319aWLVtWXPe5555rtO+sIsITLe94UU1ELJlg8cONOwIwUFwuCyRB2IEkCDuQBGEHkiDsQBIdh956ujOG3gbulFNOKdZPOqk8ILN///5etvM1X3zxRbF+6623FusPPfRQL9s5btQNvXFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdH0YUXXlis33fffcX6FVdc0fW+t2/fXqzPnTu3620fzxhnB5Ij7EAShB1IgrADSRB2IAnCDiRB2IEkGGcfAlOnTi3WP/vsswF1cuymT6+d+UuStHr16tra4sWLG+179uzZxfroaMdfNz8uMc4OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0l0nMUVzY2MjBTrL730UrH+9NNPF+ubN2+urXUaa16+fHmxfvLJJxfrnca6582bV6yXfPDBB8V61nH0bnU8stueY3uj7S2237H942r5mbaft/1edVu+ugJAqyZzGn9I0j9ExJ9J+itJP7L955LukLQhIi6QtKF6DGBIdQx7RIxGxOvV/QOStkiaLWmxpDXV09ZIurZfTQJo7pjes9ueK2mBpN9LOiciRqWx/xBsn12zzgpJK5q1CaCpSYfd9jRJ6yT9JCL22xNea3+UiFglaVW1Db4IA7RkUkNvtk/WWNB/FRFPVIv32J5Z1WdK2tufFgH0Qscju8cO4Q9L2hIRvxhXekrSUkn3VrdP9qXD48D1119frJ977rnF+o033tjLdo5JpzO4Jl+RPnjwYLF+0003db1tHG0yp/GXSfo7SW/bfrNatlJjIf+N7eWStksq/4sG0KqOYY+IlyTV/ff+3d62A6BfuFwWSIKwA0kQdiAJwg4kQdiBJPiK6wCcddZZbbfQN+vWrSvW77nnntra3r3l67B2797dVU+YGEd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCKZsHoNPPMV955ZXF+g033FCsz5o1q7b26aefFtft5IEHHijWX3zxxWL90KFDjfaPY8eUzUByhB1IgrADSRB2IAnCDiRB2IEkCDuQBOPswHGGcXYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKJj2G3Psb3R9hbb79j+cbX8Lts7bb9Z/V3d/3YBdKvjRTW2Z0qaGRGv2z5N0muSrpX0t5IORsS/THpnXFQD9F3dRTWTmZ99VNJodf+A7S2SZve2PQD9dkzv2W3PlbRA0u+rRTfbfsv2atvTa9ZZYXuT7U2NOgXQyKSvjbc9TdJ/SvpZRDxh+xxJ+ySFpHs0dqp/Y4dtcBoP9Fndafykwm77ZEm/k/RcRPxigvpcSb+LiL/osB3CDvRZ11+EsW1JD0vaMj7o1Qd3h31f0uamTQLon8l8Gn+5pBclvS3pq2rxSklLJF2ksdP4bZJ+WH2YV9oWR3agzxqdxvcKYQf6j++zA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuj4g5M9tk/Sf497PKNaNoyGtbdh7Uuit271srfz6woD/T77UTu3N0XEwtYaKBjW3oa1L4neujWo3jiNB5Ig7EASbYd9Vcv7LxnW3oa1L4neujWQ3lp9zw5gcNo+sgMYEMIOJNFK2G1fZfuPtt+3fUcbPdSxvc3229U01K3OT1fNobfX9uZxy860/bzt96rbCefYa6m3oZjGuzDNeKuvXdvTnw/8PbvtEyVtlbRI0g5Jr0paEhF/GGgjNWxvk7QwIlq/AMP2X0s6KOlfD0+tZfufJX0SEfdW/1FOj4h/HJLe7tIxTuPdp97qphn/e7X42vVy+vNutHFkv0TS+xHxYUT8SdKvJS1uoY+hFxEvSPrkiMWLJa2p7q/R2D+WgavpbShExGhEvF7dPyDp8DTjrb52hb4Goo2wz5b00bjHOzRc872HpPW2X7O9ou1mJnDO4Wm2qtuzW+7nSB2n8R6kI6YZH5rXrpvpz5tqI+wTTU0zTON/l0XEX0r6G0k/qk5XMTkPShrR2ByAo5J+3mYz1TTj6yT9JCL2t9nLeBP0NZDXrY2w75A0Z9zjb0ra1UIfE4qIXdXtXkm/1djbjmGy5/AMutXt3pb7+T8RsScivoyIryT9Ui2+dtU04+sk/SoinqgWt/7aTdTXoF63NsL+qqQLbH/L9jck/UDSUy30cRTbp1YfnMj2qZK+p+GbivopSUur+0slPdliL18zLNN4100zrpZfu9anP4+Igf9Julpjn8h/IOmf2uihpq9vS/qv6u+dtnuT9JjGTuv+R2NnRMslnSVpg6T3qtszh6i3f9PY1N5vaSxYM1vq7XKNvTV8S9Kb1d/Vbb92hb4G8rpxuSyQBFfQAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/wvwpj8O76pvCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2532, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch's dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2060, grad_fn=<NllLossBackward>), tensor(0.9688))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PyTorch's `DataLoader`, if you pass `num_workers`, will use multiple threads to call your `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid\n",
    "\n",
    "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                # no backwards - not calculating gradients for the \n",
    "                # validation set\n",
    "                tot_loss += loss_func(pred, yb) # keep track of loss\n",
    "                tot_acc  += accuracy (pred,yb) # keep track of acc\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: Are these validation results correct if batch size varies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You need to actually weight according to the size of the minibatch\n",
    "if you get the accuracy and loss for minibatch of 1 vs minibatch of 10001, can't really compare the two\n",
    "\n",
    "However, this is how almost every library does it\n",
    "\n",
    "Does NOT work correctly when you batch size varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question - why do you have to zero out your gradients in pytorch?\n",
    "\n",
    "If we didn't zero out, when we go loss.backwards will add the new gradients to the existing gradients\n",
    "\n",
    "We often have lots of sources of gradients, lots of modules all connected together\n",
    "\n",
    "When we call backward we wouldn't want backward to zero the gradients\n",
    "\n",
    "We need the grad.zero after calling backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2141) tensor(0.9415)\n",
      "1 tensor(0.1781) tensor(0.9507)\n",
      "2 tensor(0.1783) tensor(0.9537)\n",
      "3 tensor(0.5228) tensor(0.8956)\n",
      "4 tensor(0.1647) tensor(0.9539)\n"
     ]
    }
   ],
   "source": [
    "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks \n",
    "\n",
    "Callbacks let you fully customize every one of the steps\n",
    "- Model\n",
    "- Loss\n",
    "- Gradients\n",
    "- Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "nh,bs = 50,64\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor out the connected pieces of info out of the fit() argument list\n",
    "\n",
    "`fit(epochs, model, loss_func, opt, train_dl, valid_dl)`\n",
    "\n",
    "Let's replace it with something that looks like this:\n",
    "\n",
    "`fit(1, learn)`\n",
    "\n",
    "This will allow us to tweak what's happening inside the training loop in other places of the code because the `Learner` object will be mutable, so changing any of its attribute elsewhere will be seen in our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl, c=None):\n",
    "        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n",
    "        \n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "        \n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data, lr=0.5, nh=50):\n",
    "    m = data.train_ds.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,data.c))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner has no logic at all - just a storage device for model, optimizer, loss function and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact same thing, except now we access our tools we need from \n",
    "# learn where we stored all our stuff in previously\n",
    "\n",
    "def fit(epochs, learn):\n",
    "    for epoch in range(epochs):\n",
    "        learn.model.train()\n",
    "        for xb,yb in learn.data.train_dl:\n",
    "            loss = learn.loss_func(learn.model(xb), yb)\n",
    "            loss.backward()\n",
    "            learn.opt.step()\n",
    "            learn.opt.zero_grad()\n",
    "\n",
    "        learn.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in learn.data.valid_dl:\n",
    "                pred = learn.model(xb)\n",
    "                tot_loss += learn.loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(learn.data.valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3427) tensor(0.8992)\n"
     ]
    }
   ],
   "source": [
    "loss,acc = fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_batch(xb, yb, cb):\n",
    "    if not cb.begin_batch(xb,yb): return\n",
    "    loss = cb.learn.loss_func(cb.learn.model(xb), yb)\n",
    "    if not cb.after_loss(loss): return\n",
    "    loss.backward()\n",
    "    if cb.after_backward(): cb.learn.opt.step()\n",
    "    if cb.after_step(): cb.learn.opt.zero_grad()\n",
    "\n",
    "def all_batches(dl, cb):\n",
    "    for xb,yb in dl:\n",
    "        one_batch(xb, yb, cb)\n",
    "        if cb.do_stop(): return\n",
    "\n",
    "def fit(epochs, learn, cb):\n",
    "    if not cb.begin_fit(learn): return\n",
    "    for epoch in range(epochs):\n",
    "        if not cb.begin_epoch(epoch): continue\n",
    "        all_batches(learn.data.train_dl, cb)\n",
    "        \n",
    "        if cb.begin_validate():\n",
    "            with torch.no_grad(): all_batches(learn.data.valid_dl, cb)\n",
    "        if cb.do_stop() or not cb.after_epoch(): break\n",
    "    cb.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self): return True\n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    def begin_validate(self): return True\n",
    "    def after_epoch(self): return True\n",
    "    def begin_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    def after_backward(self): return True\n",
    "    def after_step(self): return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackHandler():\n",
    "    def __init__(self,cbs=None):\n",
    "        self.cbs = cbs if cbs else []\n",
    "\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn,self.in_train = learn,True\n",
    "        learn.stop = False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
    "        return res\n",
    "\n",
    "    def after_fit(self):\n",
    "        res = not self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_fit()\n",
    "        return res\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.learn.model.train()\n",
    "        self.in_train=True\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
    "        return res\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.learn.model.eval()\n",
    "        self.in_train=False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_validate()\n",
    "        return res\n",
    "\n",
    "    def after_epoch(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_epoch()\n",
    "        return res\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
    "        return res\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        res = self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
    "        return res\n",
    "\n",
    "    def after_backward(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_backward()\n",
    "        return res\n",
    "\n",
    "    def after_step(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_step()\n",
    "        return res\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     return self.learn.stop\n",
    "        finally: self.learn.stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def begin_fit(self,learn):\n",
    "        super().begin_fit(learn)\n",
    "        self.n_iters = 0\n",
    "        return True\n",
    "        \n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters>=10: self.learn.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "fit(1, learn, cb = CallbackHandler([TestCallback()])) # batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        if self('begin_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): return\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: return\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        if self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        for xb,yb in dl:\n",
    "            if self.stop: break\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        self.stop=False\n",
    "\n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn = epochs,learn\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            if self('begin_fit'): return\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
    "                if self('after_epoch'): break\n",
    "            \n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            f = getattr(cb, cb_name, None)\n",
    "            if f and f(): return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing\n",
    "\n",
    "We define two new callbacks: the Recorder to save track of the loss and our scheduled learning rate, and a ParamScheduler that can schedule any hyperparameter as long as it's registered in the state_dict of the optimizer. \n",
    "\n",
    "Hyperparameter scheduling - learning rate\n",
    "\n",
    "You can and should schedule everything - dropout amount, weight decay, learning rate, momentum, everything\n",
    "\n",
    "Different phases in the loss landscapes of neural nets - look very different at the start, middle, and end \n",
    "\n",
    "Very unlikely that you want the same things for all parts of training so being able to schedule things is a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Recorder(Callback): # at the start of fitting, sets losses and lrs to empty\n",
    "    def begin_fit(self): self.lrs,self.losses = [],[]\n",
    "\n",
    "        # when training append the current lr and loss\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr']) # this is the final layer group learning rate\n",
    "        self.losses.append(self.loss.detach().cpu())        \n",
    "\n",
    "    def plot_lr  (self): plt.plot(self.lrs)\n",
    "    def plot_loss(self): plt.plot(self.losses)\n",
    "\n",
    "class ParamScheduler(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, pname, sched_func): self.pname,self.sched_func = pname,sched_func\n",
    "\n",
    "    def set_param(self):\n",
    "        for pg in self.opt.param_groups: # layer groups = param groups; pytorch optimizer contains param_groups, loop through\n",
    "            pg[self.pname] = self.sched_func(self.n_epochs/self.epochs)\n",
    "    \n",
    "    # this says everytime we start a batch, run our scheduler\n",
    "    def begin_batch(self): \n",
    "        if self.in_train: self.set_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sched_lin(start, end):\n",
    "    def _inner(start, end, pos): return start + pos * (end-start)\n",
    "    return partial(_inner, start, end)\n",
    "# the function takes a start end and position of learning rate, returns a learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor this with a decorator\n",
    "\n",
    "def annealer(f):\n",
    "    def _inner(start, end): return partial(f, start, end)\n",
    "    return _inner\n",
    "\n",
    "@annealer\n",
    "def sched_lin(start, end, pos): return start + pos * (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decorator is a function that returns a function\n",
    "Takes the written function, passes it into the function called with the '@' sign, and replaces the definition of the function with whatever is returned"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sched_lin() # use shift - tab; see that it takes only start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = sched_lin(1,2)\n",
    "f(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other scheduler functions\n",
    "@annealer\n",
    "def sched_cos(start, end, pos): return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2\n",
    "@annealer\n",
    "def sched_no(start, end, pos):  return start\n",
    "@annealer\n",
    "def sched_exp(start, end, pos): return start * (end/start) ** pos\n",
    "\n",
    "def cos_1cycle_anneal(start, high, end):\n",
    "    return [sched_cos(start, high), sched_cos(high, end)]\n",
    "\n",
    "#This monkey-patch is there to be able to plot tensors\n",
    "torch.Tensor.ndim = property(lambda x: len(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annealings = \"NO LINEAR COS EXP\".split()\n",
    "\n",
    "a = torch.arange(0, 100)\n",
    "p = torch.linspace(0.01,1,100)\n",
    "\n",
    "fns = [sched_no, sched_lin, sched_cos, sched_exp]\n",
    "for fn, t in zip(fns, annealings):\n",
    "    f = fn(2, 1e-2)\n",
    "    plt.plot(a, [f(o) for o in p], label=t)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine different schedulers (might want a warm up and cool down type scheduler)\n",
    "def combine_scheds(pcts, scheds):\n",
    "    assert sum(pcts) == 1.\n",
    "    pcts = tensor([0] + listify(pcts))\n",
    "    assert torch.all(pcts >= 0)\n",
    "    pcts = torch.cumsum(pcts, 0)\n",
    "    def _inner(pos):\n",
    "        idx = (pos >= pcts).nonzero().max()\n",
    "        if idx == 2: idx = 1\n",
    "        actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])\n",
    "        return scheds[idx](actual_pos)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3,0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b59d3907510>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, [sched(o) for o in p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to train at a high learning rate for a long time, but you also want to train at a very low learning rate for a long time, and you want a gentle learning rate at the beginning when things are fragile.\n",
    "\n",
    "Therefore, want cosine scheduler to warm up and cool down our learning rates as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train): self.metrics,self.in_train = listify(metrics),in_train\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tot_loss,self.count = 0.,0\n",
    "        self.tot_mets = [0.] * len(self.metrics)\n",
    "        \n",
    "    @property\n",
    "    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
    "    @property\n",
    "    def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb) * bn\n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [Recorder,\n",
    "        partial(AvgStatsCallback,accuracy),\n",
    "        partial(ParamScheduler, 'lr', sched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner(model_func, loss_func, data):\n",
    "    return Learner(*model_func(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_func(lr=0.5): return partial(get_model, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner(get_model, loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    _order=0\n",
    "    def set_runner(self, run): self.run=run\n",
    "    def __getattr__(self, k): return getattr(self.run, k)\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "    \n",
    "    def __call__(self, cb_name): # takes any callback that a user might make\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f(): return True # users can replace __call__ itself\n",
    "        return False # makes this more flexible\n",
    "\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False\n",
    "\n",
    "class CancelTrainException(Exception): pass # let peoples callbacks cancel at any of these levels \n",
    "class CancelEpochException(Exception): pass # example, can cancel one epoch but continue to the next one\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        self.in_train = False\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        try:\n",
    "            self.xb,self.yb = xb,yb\n",
    "            self('begin_batch')\n",
    "            self.pred = self.model(self.xb)\n",
    "            self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb)\n",
    "            self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.opt.step()\n",
    "            self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException: self('after_cancel_batch')\n",
    "        finally: self('after_batch')\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        try:\n",
    "            for xb,yb in dl: self.one_batch(xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn,self.loss = epochs,learn,tensor(0.)\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            self('begin_fit')\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
    "                self('after_epoch')\n",
    "            \n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit') \n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on use of Exceptions\n",
    "\n",
    "Exceptions in this usage allow the callback writer to stop any of the main parts from things happening.\n",
    "\n",
    "In this example, will use it to stop training in order to create a learning rate finder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    _order=1\n",
    "    def after_step(self):\n",
    "        print(self.n_iter)\n",
    "        if self.n_iter>=10: raise CancelTrainException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(cb_funcs=TestCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some other callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)\n",
    "        \n",
    "class Recorder(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.lrs = [[] for _ in self.opt.param_groups]\n",
    "        self.losses = []\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        for pg,lr in zip(self.opt.param_groups,self.lrs): lr.append(pg['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())        \n",
    "\n",
    "    def plot_lr  (self, pgid=-1): plt.plot(self.lrs[pgid])\n",
    "    def plot_loss(self, skip_last=0): plt.plot(self.losses[:len(self.losses)-skip_last])\n",
    "        \n",
    "    def plot(self, skip_last=0, pgid=-1):\n",
    "        losses = [o.item() for o in self.losses]\n",
    "        lrs    = self.lrs[pgid]\n",
    "        n = len(losses)-skip_last\n",
    "        plt.xscale('log')\n",
    "        plt.plot(lrs[:n], losses[:n])\n",
    "\n",
    "class ParamScheduler(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, pname, sched_funcs): self.pname,self.sched_funcs = pname,sched_funcs\n",
    "        \n",
    "    def begin_fit(self):\n",
    "        if not isinstance(self.sched_funcs, (list,tuple)):\n",
    "            self.sched_funcs = [self.sched_funcs] * len(self.opt.param_groups)\n",
    "\n",
    "    def set_param(self):\n",
    "        assert len(self.opt.param_groups)==len(self.sched_funcs)\n",
    "        for pg,f in zip(self.opt.param_groups,self.sched_funcs):\n",
    "            pg[self.pname] = f(self.n_epochs/self.epochs)\n",
    "            \n",
    "    def begin_batch(self): \n",
    "        if self.in_train: self.set_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Learning Rate Finder from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to also add something that saves the model before running this, and loads it back after running - **otherwise you'll lose your weights!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Find(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
    "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
    "        self.best_loss = 1e9\n",
    "    # in begin batch, uses exponential curve to set the learning rate    \n",
    "    def begin_batch(self): \n",
    "        if not self.in_train: return\n",
    "        pos = self.n_iter/self.max_iter\n",
    "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos # curve to set lr\n",
    "        for pg in self.opt.param_groups: pg['lr'] = lr\n",
    "    # after each step, checks to see if we've done more than the maximum number of iterations (default is 100)     \n",
    "    def after_step(self): # or, whether the loss is much worse than the best we've had \n",
    "        # if EITHER happens, we raise CancelTrainException, which cancels training\n",
    "        if self.n_iter>=self.max_iter or self.loss>self.best_loss*10:\n",
    "            raise CancelTrainException() # this cancels training once you've found your learning rate!\n",
    "        if self.loss < self.best_loss: self.best_loss = self.loss\n",
    "        # see if the loss is better than our best loss - if so, make this better loss our new loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fastai we also use exponential smoothing on the loss. For that reason we check for `best_loss*3` instead of `best_loss*10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner(get_model, loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(cb_funcs=[LR_Find, Recorder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.recorder.plot(skip_last=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only does less than 100 epochs, knnow around where we want to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make it Convolutional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to(train, valid):\n",
    "    m,s = train.mean(), train.std()\n",
    "    return normalize(train, m, s), normalize(valid, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = normalize_to(x_train, x_valid)\n",
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0001), tensor(1.))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When refactoring, use ```Lambda``` layer that takes a basic function input and converts this to a layer that you can add to ```nn.Sequential```.\n",
    "\n",
    "Best to give a name to the function you're using inside of your Lambda (like flatten below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x): return self.func(x)\n",
    "    \n",
    "def flatten(x): return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes flat vector of size bs x 784, puts it back as batch of images in \n",
    "# 28 by 28 pixel resolution\n",
    "def mnist_resize(x): return x.view(-1,1,28,28) # .view resizes stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(data):\n",
    "    return nn.Sequential(\n",
    "        Lambda(mnist_resize),\n",
    "        nn.Conv2d(1, 8, 5, padding=2, stride=2), nn.ReLU(), #14\n",
    "        nn.Conv2d(8, 16, 3, padding=1, stride=2), nn.ReLU(), #7\n",
    "        nn.Conv2d(16, 32, 3, padding=1, stride =2), nn.ReLU(), #4\n",
    "        nn.Conv2d(32, 32, 3, padding=1, stride =2), nn.ReLU(), #2\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(flatten),\n",
    "        nn.Linear(32, data.c)\n",
    "    )\n",
    "\n",
    "# sequential model that contains a bunch of stride 2 convolutions\n",
    "# remember = input is 28 by 28\n",
    "# So after the first convolution, input is 14 (dividing 28 in half)\n",
    "# After the second convolution, input is 7 x 7\n",
    "# then 4 x 4, 2 x 2\n",
    "# Do average pooling of all the activations\n",
    "# flatten the results\n",
    "# pass it through a linear layer\n",
    "# Done!\n",
    "\n",
    "# Use Lambda here to resize our input and flatten our output, all within nn.Sequential itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [Recorder, partial(AvgStatsCallback, accuracy)]\n",
    "# partial means I'm treating the AvgStatsCallback class like a function\n",
    "# Here I'm passing it accuracy, and from this I want it to \n",
    "# calculate the average accuracy of my performance per minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr = 0.4) # specifying our optimizer, SGD \n",
    "learn = Learner(model, opt, loss_func, data) # Create our learner, ready for training \n",
    "run = Runner(cb_funcs = cbfs) # Run our model for training, pass in our callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.4471877734375, tensor(0.8527)]\n",
      "valid: [0.577237451171875, tensor(0.8937)]\n",
      "train: [0.10073755859375, tensor(0.9698)]\n",
      "valid: [0.13612435302734374, tensor(0.9608)]\n",
      "train: [0.072993974609375, tensor(0.9770)]\n",
      "valid: [0.08973518676757812, tensor(0.9712)]\n",
      "train: [0.057587626953125, tensor(0.9825)]\n",
      "valid: [0.06235679321289062, tensor(0.9825)]\n"
     ]
    }
   ],
   "source": [
    "%timeit run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That took a long time! Let's use our GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple Callback can make sure the model, inputs and targets are all on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
